# compare-firebird-different-os

A small Python toolkit to compare the performance of two Firebird database servers running on **different operating systems** (e.g., Windows vs Linux).  
It focuses on measuring:

- Connection time
- Simple query execution time
- Repeated query benchmarks
- CSV export of raw timings
- Basic statistics per server (mean, min, max)

This is useful when you are:
- Migrating Firebird from Windows to Linux (or vice versa)
- Tuning Firebird configuration and OS settings
- Measuring network latency impact on Firebird access

---

## ğŸš€ Technologies

- **Python 3.10+**
- **uv** â€“ fast Python environment & dependency manager
- **fdb** â€“ Firebird driver for Python
- **python-dotenv** â€“ environment variable loader
- Firebird 2.5 / 3.0 / 4.0 (any version supported by `fdb`)

---

## ğŸ“¦ Setup

### 1. Install `uv` (if you donâ€™t have it yet)

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Make sure `uv` is available in your shell (you may need to reload it).

### 2. Clone the repository

```bash
git clone https://github.com/andreagnoletto/compare-firebird-different-os.git
cd compare-firebird-different-os
```

### 3. Install dependencies

```bash
uv sync
```

This will create a virtual environment and install:

- `fdb`
- `python-dotenv`

---

## âš™ï¸ Configuration

The project uses a `.env` file at the repository root.  
A template is provided as:

```text
.env.example
```

Create your own `.env` based on it:

```bash
cp .env.example .env
```

Then edit `.env` and fill in real values:

```dotenv
# FIREBIRD WINDOWS
WIN_FB_HOST=192.168.0.10
WIN_FB_PORT=3050
WIN_FB_DATABASE=C:/path/to/clinica.fdb
WIN_FB_USER=sysdba
WIN_FB_PASSWORD=YOUR_PASSWORD

# FIREBIRD LINUX
LIN_FB_HOST=192.168.0.20
LIN_FB_PORT=3050
LIN_FB_DATABASE=/var/db/firebird/clinica.fdb
LIN_FB_USER=sysdba
LIN_FB_PASSWORD=YOUR_PASSWORD

# BENCHMARK
FB_BENCH_RUNS=20
FB_BENCH_QUERY=SELECT CURRENT_TIMESTAMP FROM RDB$DATABASE
```

- On **Windows**, `WIN_FB_DATABASE` can be a full path or an alias defined in `aliases.conf`.
- On **Linux**, it is recommended to use the absolute path to the `.fdb` file.

> **Security note:** Never commit your `.env` file to version control. Only `.env.example` should be committed.

---

## â–¶ï¸ Usage

### 1. Quick connectivity test

Run:

```bash
uv run src/compare_firebird_different_os/main.py
```

This script:

- Opens a connection to each server (Windows and Linux)
- Executes a simple test query
- Prints:
  - Connection time
  - Query time
  - Total time
  - Returned timestamp for each server

### 2. Full benchmark (loop + stats + CSV)

Run:

```bash
uv run src/compare_firebird_different_os/benchmark.py
```

This script:

1. Reads `FB_BENCH_RUNS` and `FB_BENCH_QUERY` from `.env`
2. Executes the given query multiple times on:
   - the Windows Firebird server
   - the Linux Firebird server
3. Measures the execution time for each run
4. Computes statistics per server:
   - mean
   - min
   - max
5. Writes a CSV file with all measurements:

```text
firebird_benchmark_results.csv
```

CSV columns:

```text
server;run_index;elapsed_seconds;query;runs
```

You can open this CSV in Excel, LibreOffice, or import it into another tool for further analysis.

---

## ğŸ“‚ Project structure

```text
compare-firebird-different-os/
â”œâ”€ .env
â”œâ”€ .env.example
â”œâ”€ pyproject.toml
â”œâ”€ firebird_benchmark_results.csv   # generated by benchmark.py
â””â”€ src/
   â””â”€ compare_firebird_different_os/
      â”œâ”€ __init__.py
      â”œâ”€ main.py
      â””â”€ benchmark.py
```

- `main.py`: quick connectivity and single-query timing.
- `benchmark.py`: multi-run benchmark + statistics + CSV export.

---

## ğŸ” Security

- Do not commit `.env` files to your repository.
- Prefer using a dedicated Firebird user instead of `SYSDBA` in production.
- Ensure that only trusted IPs can reach the Firebird port (usually 3050).

---

## ğŸ§ª Tips for more realistic benchmarks

To get meaningful results:

- Place Windows and Linux machines on the **same physical network**, if possible.
- Use **real-world queries** on large tables:
  - `COUNT(*)` on big tables
  - `JOIN` + `ORDER BY` + `GROUP BY`
- Compare the impact of:
  - `DefaultDbCachePages`
  - `TempCacheLimit`
  - `TcpNoNagle`
  - `CpuAffinity`
  - OS-level tuning (`vm.swappiness`, dirty ratios, I/O scheduler, etc.)
- Repeat the benchmark before and after each tuning change and compare CSVs.

---

## ğŸ¤ Contributing

Contributions are welcome!  
Ideas for improvement:

- Add more benchmark modes (connection-only, transaction-heavy, mixed read/write)
- Support for more than two servers
- Graph generation (e.g., using matplotlib) from the CSV data

Feel free to open issues or pull requests.

---

## ğŸ“„ License

This project is released under the **MIT License**.  
You are free to use it for personal and commercial purposes.
